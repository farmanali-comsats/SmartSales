#! /usr/bin/env python
#  -*- coding: utf-8 -*-
#
# GUI module generated by PAGE version 6.0
#  in conjunction with Tcl version 8.6
#    Dec 16, 2020 02:56:20 PM PKT  platform: Windows NT

import sys

try:
    import Tkinter as tk
    from Tkinter import messagebox    
except ImportError:
    import tkinter as tk
    from tkinter import messagebox
    from tkinter import filedialog

try:
    import ttk
    py3 = False
except ImportError:
    import tkinter.ttk as ttk
    py3 = True

try:
    import scipy
    import numpy
    import matplotlib
    import pandas
    import sklearn
    import statsmodels
    import warnings
    from pandas import read_csv
    from matplotlib import pyplot
    from statsmodels.tsa.arima_model import ARIMA
    from statsmodels.tsa.arima_model import ARIMAResults
    from sklearn.metrics import mean_squared_error
    from math import sqrt
    from scipy.stats import boxcox
    from pandas import DataFrame
    from statsmodels.graphics.tsaplots import plot_acf
    from statsmodels.graphics.tsaplots import plot_pacf
    from pandas import Grouper
    from pandas import Series
    from statsmodels.tsa.stattools import adfuller
    import os
    from keras.models import Sequential
    from keras.layers import Dense
    from keras.layers import Dropout
    from keras.layers import Activation
    from sklearn.model_selection import train_test_split
    from pandas import concat
    from pandas import datetime
    from sklearn.preprocessing import MinMaxScaler
    from keras.layers import LSTM
except ImportError:
    import scipy
    import numpy
    import matplotlib
    import pandas
    import sklearn
    import statsmodels
    import warnings
    from pandas import read_csv
    from matplotlib import pyplot
    from statsmodels.tsa.arima_model import ARIMA
    from statsmodels.tsa.arima_model import ARIMAResults
    from sklearn.metrics import mean_squared_error
    from math import sqrt
    from scipy.stats import boxcox
    from pandas import DataFrame
    from statsmodels.graphics.tsaplots import plot_acf
    from statsmodels.graphics.tsaplots import plot_pacf
    from pandas import Grouper
    from pandas import Series
    from statsmodels.tsa.stattools import adfuller
    import os
    from keras.models import Sequential
    from keras.layers import Dense
    from keras.layers import Dropout
    from keras.layers import Activation
    from sklearn.model_selection import train_test_split
    from pandas import concat
    from pandas import datetime
    from sklearn.preprocessing import MinMaxScaler
    from keras.layers import LSTM

import predictsales_ari_support

def vp_start_gui():
    '''Starting point when module is the main routine.'''
    global val, w, root
    root = tk.Tk()
    top = Toplevel1 (root)
    predictsales_ari_support.init(root, top)
    root.mainloop()

w = None
def create_Toplevel1(rt, *args, **kwargs):
    '''Starting point when module is imported by another module.
       Correct form of call: 'create_Toplevel1(root, *args, **kwargs)' .'''
    global w, w_win, root
    #rt = root
    root = rt
    w = tk.Toplevel (root)
    top = Toplevel1 (w)
    predictsales_ari_support.init(w, top, *args, **kwargs)
    return (w, top)

def destroy_Toplevel1():
    global w
    w.destroy()
    w = None

def startpredictiondaily():
    try:
        #Import sample dataset containing date, year, day of the week, day of the montn, holydays and sales (i.e. #loans sold)
        #df = read_csv('Daily_sales.csv',delimiter=';',index_col='date')
        #series = read_csv(loaddataset, header=None,skiprows=1, index_col=0, parse_dates=True, squeeze=True)
        dates = df.index
        #Split targets and features
        Y = df.iloc[:,6]
        X = df.iloc[:,0:6]
        
        #Split train and test
        X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, shuffle=True)
        
        #Count features for modelization
        X_num_columns= len(X.columns)
        
        #Define model
        model = Sequential()
        
        model.add(Dense(300,
                        activation='relu',
                        input_dim = X_num_columns))
        
        model.add(Dense(90,
                        activation='relu'))
        model.add(Dropout(0.2))
        
        model.add(Dense(30,
                        activation='relu'))
        model.add(Dropout(0.2))
        
        model.add(Dense(7,
                        activation='relu'))
        model.add(Dropout(0.2))
        
        model.add(Dense(1,
                        activation='linear'))
        
        model.compile(optimizer='adam', loss='mean_squared_error')
        print("Model Created")
        
        #Fit model to training data
        model.fit(X_train, y_train, epochs=5000, batch_size=100)
        print("Training completed")
        
        #Save trained model
        model.save("Sales_model.h5")
        print("Sales_dailymodel.h5 saved model to disk in ",os.getcwd())
        
        #Predict known daily sales in order to check results
        predictions = model.predict(X)
        predictions_list = map(lambda x: x[0], predictions)
        predictions_series = Series(predictions_list,index=dates)
        dates_series =  Series(dates)
        
        #Import dates to be predicted
        df_newDates = read_csv('Upcoming_dates.csv',delimiter=';',index_col='date')
        print("Upcoming dates imported")
        
        #Predict upcoming sales using trained model and imported upcoming dates
        Predicted_sales = model.predict(df_newDates)
        
        #Export predicted sales
        new_dates_series=Series(df_newDates.index)
        new_predictions_list = map(lambda x: x[0], Predicted_sales)
        new_predictions_series = Series(new_predictions_list,index=new_dates_series)
        new_predictions_series.to_csv("predictiondaily.csv")
        messagebox.showinfo("Completed","Successfully Forecasted Sales")
    except Exception as e:
        messagebox.showerror(str(e))

def startpredictionrnn():
    try:
        # date-time parsing function for loading the dataset
        def parser(x):
        	return datetime.strptime('190'+x, '%Y-%m')
        
        # frame a sequence as a supervised learning problem
        def timeseries_to_supervised(data, lag=1):
        	df = DataFrame(data)
        	columns = [df.shift(i) for i in range(1, lag+1)]
        	columns.append(df)
        	df = concat(columns, axis=1)
        	df.fillna(0, inplace=True)
        	return df
        
        # create a differenced series
        def difference(dataset, interval=1):
        	diff = list()
        	for i in range(interval, len(dataset)):
        		value = dataset[i] - dataset[i - interval]
        		diff.append(value)
        	return Series(diff)
        
        # invert differenced value
        def inverse_difference(history, yhat, interval=1):
        	return yhat + history[-interval]
        
        # scale train and test data to [-1, 1]
        def scale(train, test):
        	# fit scaler
        	scaler = MinMaxScaler(feature_range=(-1, 1))
        	scaler = scaler.fit(train)
        	# transform train
        	train = train.reshape(train.shape[0], train.shape[1])
        	train_scaled = scaler.transform(train)
        	# transform test
        	test = test.reshape(test.shape[0], test.shape[1])
        	test_scaled = scaler.transform(test)
        	return scaler, train_scaled, test_scaled
        
        # inverse scaling for a forecasted value
        def invert_scale(scaler, X, value):
        	new_row = [x for x in X] + [value]
        	array = numpy.array(new_row)
        	array = array.reshape(1, len(array))
        	inverted = scaler.inverse_transform(array)
        	return inverted[0, -1]
        
        # fit an LSTM network to training data
        def fit_lstm(train, batch_size, nb_epoch, neurons):
        	X, y = train[:, 0:-1], train[:, -1]
        	X = X.reshape(X.shape[0], 1, X.shape[1])
        	model = Sequential()
        	model.add(LSTM(neurons, batch_input_shape=(batch_size, X.shape[1], X.shape[2]), stateful=True))
        	model.add(Dense(1))
        	model.compile(loss='mean_squared_error', optimizer='adam')
        	for i in range(nb_epoch):
        		model.fit(X, y, epochs=1, batch_size=batch_size, verbose=0, shuffle=False)
        		model.reset_states()
        	return model
        
        # make a one-step forecast
        def forecast_lstm(model, batch_size, X):
        	X = X.reshape(1, 1, len(X))
        	yhat = model.predict(X, batch_size=batch_size)
        	return yhat[0,0]
        
        # load dataset
        #series = read_csv('shampoo.csv', header=0, parse_dates=[0], index_col=0, squeeze=True, date_parser=parser)
        
        # transform data to be stationary
        raw_values = rnnseries.values
        diff_values = difference(raw_values, 1)
        
        # transform data to be supervised learning
        supervised = timeseries_to_supervised(diff_values, 1)
        supervised_values = supervised.values
        
        # split data into train and test-sets
        train, test = supervised_values[0:-12], supervised_values[-12:]
        
        # transform the scale of the data
        scaler, train_scaled, test_scaled = scale(train, test)
        
        # fit the model
        lstm_model = fit_lstm(train_scaled, 1, 3000, 4)
        # forecast the entire training dataset to build up state for forecasting
        train_reshaped = train_scaled[:, 0].reshape(len(train_scaled), 1, 1)
        lstm_model.predict(train_reshaped, batch_size=1)
        
        # walk-forward validation on the test data
        predictions = list()
        for i in range(len(test_scaled)):
        	# make one-step forecast
        	X, y = test_scaled[i, 0:-1], test_scaled[i, -1]
        	yhat = forecast_lstm(lstm_model, 1, X)
        	# invert scaling
        	yhat = invert_scale(scaler, X, yhat)
        	# invert differencing
        	yhat = inverse_difference(raw_values, yhat, len(test_scaled)+1-i)
        	# store forecast
        	predictions.append(yhat)
        	expected = raw_values[len(train) + i + 1]
        	print('Month=%d, Predicted=%f, Expected=%f' % (i+1, yhat, expected))
        prediction = DataFrame(predictions, columns=['predictions']).to_csv('predictionbyrnn.csv')
        
        # report performance
        rmse = sqrt(mean_squared_error(raw_values[-12:], predictions))
        print('Test RMSE: %.3f' % rmse)
        # line plot of observed vs predicted
        pyplot.plot(raw_values[-12:])
        pyplot.plot(predictions)
        pyplot.show()
        messagebox.showinfo("Completed","Successfully Forecasted Sales")
    except Exception as e:
        messagebox.showerror(str(e))

def startpredictionarima():
    try:
        # separate out a validation dataset
        series = read_csv('sales_data.csv', header=0, index_col=0, parse_dates=True, squeeze=True)
        split_point = len(series) - 12
        dataset, validation = series[0:split_point], series[split_point:]
        print('Dataset %d, Validation %d' % (len(dataset), len(validation)))
        dataset.to_csv('dataset.csv', header=False)
        validation.to_csv('validation.csv', header=False)
        
        
        ...
        test = [0, 0, 0]
        predictions = [0, 0, 0]
        mse = mean_squared_error(test, predictions)
        rmse = sqrt(mse)
        print('RMSE: %.3f' % rmse)
        s_rmse = str(rmse)
        #print('RMSE: %.3f' % s_rmse)
        
        # prepare data
        X = series.values
        X = X.astype('float32')
        train_size = int(len(X) * 0.50)
        train, test = X[0:train_size], X[train_size:]
        
        # walk-forward validation
        history = [x for x in train]
        predictions = list()
        for i in range(len(test)):
            # predict
            yhat = 0
            predictions.append(yhat)
            # observation
            obs = test[i]
            history.append(obs)
            print('>Predicted=%.3f, Expected=%3.f' % (yhat, obs))
        
        
        
        # load data
        series = read_csv('dataset.csv', header=None, index_col=0, parse_dates=True, squeeze=True)
        # prepare data
        X = series.values
        X = X.astype('float32')
        train_size = int(len(X) * 0.50)
        train, test = X[0:train_size], X[train_size:]
        # walk-forward validation
        history = [x for x in train]
        predictions = list()
        for i in range(len(test)):
            # predict
            yhat = history[-1]
            predictions.append(yhat)
            # observation
            obs = test[i]
            history.append(obs)
            print('>Predicted=%.3f, Expected=%3.f' % (yhat, obs))
        # report performance
        mse = mean_squared_error(test, predictions)
        rmse = sqrt(mse)
        print('RMSE: %.3f' % rmse)    
        
        
        series = read_csv('dataset.csv', header=None, index_col=0, parse_dates=True, squeeze=True)
        print(series.describe())
        
        
        
        series = read_csv('dataset.csv', header=None, index_col=0, parse_dates=True, squeeze=True)
        series.plot()
        pyplot.savefig('figure1.png')
        
        
        
        series = read_csv('dataset.csv', header=None, index_col=0, parse_dates=True, squeeze=True)
        groups = series['1964':'1970'].groupby(Grouper(freq='A'))
        years = DataFrame()
        pyplot.figure()
        i = 1
        n_groups = len(groups)
        for name, group in groups:
            pyplot.subplot((n_groups*100) + 10 + i)
            i += 1
            pyplot.plot(group)
        pyplot.savefig('figure2.png')
        
        
        
        series = read_csv('dataset.csv', header=None, index_col=0, parse_dates=True, squeeze=True)
        pyplot.figure(1)
        pyplot.subplot(211)
        series.hist()
        pyplot.subplot(212)
        series.plot(kind='kde')
        pyplot.savefig('figure3.png')
        
        
        
        series = read_csv('dataset.csv', header=None, index_col=0, parse_dates=True, squeeze=True)
        groups = series['1964':'1970'].groupby(Grouper(freq='A'))
        years = DataFrame()
        for name, group in groups:
            years[name.year] = group.values
        years.boxplot()
        pyplot.savefig('figure4.png')
        
        
        # create a differenced series
        def difference(dataset, interval=1):
            diff = list()
            for i in range(interval, len(dataset)):
                value = dataset[i] - dataset[i - interval]
                diff.append(value)
            return Series(diff)
        
        series = read_csv('dataset.csv', header=None, index_col=0, parse_dates=True, squeeze=True)
        X = series.values
        X = X.astype('float32')
        # difference data
        months_in_year = 12
        stationary = difference(X, months_in_year)
        stationary.index = series.index[months_in_year:]
        # check if stationary
        result = adfuller(stationary)
        print('ADF Statistic: %f' % result[0])
        print('p-value: %f' % result[1])
        print('Critical Values:')
        for key, value in result[4].items():
            print('\t%s: %.3f' % (key, value))
        # save
        stationary.to_csv('stationary.csv', header=False)
        # plot
        stationary.plot()
        pyplot.savefig('figure5.png')
        
        # invert differenced value
        def inverse_difference(history, yhat, interval=1):
            return yhat + history[-interval]
        
        
        series = read_csv('stationary.csv', header=None, index_col=0, parse_dates=True, squeeze=True)
        pyplot.figure()
        pyplot.subplot(211)
        plot_acf(series, ax=pyplot.gca())
        pyplot.subplot(212)
        plot_pacf(series, ax=pyplot.gca())
        pyplot.savefig('figure6.png')
        
        
        # create a differenced series
        def difference(dataset, interval=1):
            diff = list()
            for i in range(interval, len(dataset)):
                value = dataset[i] - dataset[i - interval]
                diff.append(value)
            return diff
        
        
        # load data
        series = read_csv('dataset.csv', header=None, index_col=0, parse_dates=True, squeeze=True)
        # prepare data
        X = series.values
        X = X.astype('float32')
        train_size = int(len(X) * 0.50)
        train, test = X[0:train_size], X[train_size:]
        # walk-forward validation
        history = [x for x in train]
        predictions = list()
        for i in range(len(test)):
            # difference data
            months_in_year = 12
            diff = difference(history, months_in_year)
            # predict
            model = ARIMA(diff, order=(1,1,1))
            model_fit = model.fit(trend='nc', disp=0)
            yhat = model_fit.forecast()[0]
            yhat = inverse_difference(history, yhat, months_in_year)
            predictions.append(yhat)
            # observation
            obs = test[i]
            history.append(obs)
            print('>Predicted=%.3f, Expected=%3.f' % (yhat, obs))
        # report performance
        mse = mean_squared_error(test, predictions)
        rmse = sqrt(mse)
        print('RMSE: %.3f' % rmse)
        
        
        # create a differenced series
        def difference(dataset, interval=1):
            diff = list()
            for i in range(interval, len(dataset)):
                value = dataset[i] - dataset[i - interval]
                diff.append(value)
            return numpy.array(diff)
        
        
        # evaluate an ARIMA model for a given order (p,d,q) and return RMSE
        def evaluate_arima_model(X, arima_order):
            # prepare training dataset
            X = X.astype('float32')
            train_size = int(len(X) * 0.50)
            train, test = X[0:train_size], X[train_size:]
            history = [x for x in train]
            # make predictions
            predictions = list()
            for t in range(len(test)):
                # difference data
                months_in_year = 12
                diff = difference(history, months_in_year)
                model = ARIMA(diff, order=arima_order)
                model_fit = model.fit(trend='nc', disp=0)
                yhat = model_fit.forecast()[0]
                yhat = inverse_difference(history, yhat, months_in_year)
                predictions.append(yhat)
                history.append(test[t])
            # calculate out of sample error
            mse = mean_squared_error(test, predictions)
            rmse = sqrt(mse)
            return rmse
        
        # evaluate combinations of p, d and q values for an ARIMA model
        def evaluate_models(dataset, p_values, d_values, q_values):
            dataset = dataset.astype('float32')
            best_score, best_cfg = float("inf"), None
            global mset
            mset = None
            for p in p_values:
                for d in d_values:
                    for q in q_values:
                        order = (p,d,q)
                        try:
                            mse = evaluate_arima_model(dataset, order)
                            if mse < best_score:
                                best_score, best_cfg = mse, order
                                mset = order
                            print('ARIMA%s RMSE=%.3f' % (order,mse))
                        except:
                            continue
            print('Best ARIMA%s RMSE=%.3f' % (best_cfg, best_score))
            #myset = best_cfg
            print(mset)
        
        # load dataset
        series = read_csv('dataset.csv', header=None, index_col=0, parse_dates=True, squeeze=True)
        # evaluate parameters
        p_values = range(0, 7)
        d_values = range(0, 3)
        q_values = range(0, 7)
        warnings.filterwarnings("ignore")
        evaluate_models(series.values, p_values, d_values, q_values)
        
        
        
        # create a differenced series
        def difference(dataset, interval=1):
            diff = list()
            for i in range(interval, len(dataset)):
                value = dataset[i] - dataset[i - interval]
                diff.append(value)
            return diff
        
        # invert differenced value
        
        
        
        # load data
        series = read_csv('dataset.csv', header=None, index_col=0, parse_dates=True, squeeze=True)
        # prepare data
        X = series.values
        X = X.astype('float32')
        train_size = int(len(X) * 0.50)
        train, test = X[0:train_size], X[train_size:]
        # walk-forward validation
        history = [x for x in train]
        predictions = list()
        for i in range(len(test)):
            # difference data
            months_in_year = 12
            diff = difference(history, months_in_year)
            # predict
            model = ARIMA(diff, mset)
            model_fit = model.fit(trend='nc', disp=0)
            yhat = model_fit.forecast()[0]
            yhat = inverse_difference(history, yhat, months_in_year)
            predictions.append(yhat)
            # observation
            obs = test[i]
            history.append(obs)
        # errors
        residuals = [test[i]-predictions[i] for i in range(len(test))]
        residuals = DataFrame(residuals)
        print(residuals.describe())
        # plot
        pyplot.figure()
        pyplot.subplot(211)
        residuals.hist(ax=pyplot.gca())
        pyplot.subplot(212)
        residuals.plot(kind='kde', ax=pyplot.gca())
        pyplot.savefig('figure7.png')
        
        
        
        # create a differenced series
        def difference(dataset, interval=1):
            diff = list()
            for i in range(interval, len(dataset)):
                value = dataset[i] - dataset[i - interval]
                diff.append(value)
            return diff
        
        # invert differenced value
        
        
        
        # load data
        series = read_csv('dataset.csv', header=None, index_col=0, parse_dates=True, squeeze=True)
        # prepare data
        X = series.values
        X = X.astype('float32')
        train_size = int(len(X) * 0.50)
        train, test = X[0:train_size], X[train_size:]
        # walk-forward validation
        history = [x for x in train]
        predictions = list()
        bias = 86.775863
        for i in range(len(test)):
            # difference data
            months_in_year = 12
            diff = difference(history, months_in_year)
            # predict
            model = ARIMA(diff, mset)
            model_fit = model.fit(trend='nc', disp=0)
            yhat = model_fit.forecast()[0]
            yhat = bias + inverse_difference(history, yhat, months_in_year)
            predictions.append(yhat)
            # observation
            obs = test[i]
            history.append(obs)
        # report performance
        mse = mean_squared_error(test, predictions)
        rmse = sqrt(mse)
        print('RMSE: %.3f' % rmse)
        # errors
        residuals = [test[i]-predictions[i] for i in range(len(test))]
        residuals = DataFrame(residuals)
        print(residuals.describe())
        # plot
        pyplot.figure()
        pyplot.subplot(211)
        residuals.hist(ax=pyplot.gca())
        pyplot.subplot(212)
        residuals.plot(kind='kde', ax=pyplot.gca())
        pyplot.savefig('figure8.png')
        
        
        
        # create a differenced series
        def difference(dataset, interval=1):
            diff = list()
            for i in range(interval, len(dataset)):
                value = dataset[i] - dataset[i - interval]
                diff.append(value)
            return diff
        
        # invert differenced value
        
        
        
        # load data
        series = read_csv('dataset.csv', header=None, index_col=0, parse_dates=True, squeeze=True)
        # prepare data
        X = series.values
        X = X.astype('float32')
        train_size = int(len(X) * 0.50)
        train, test = X[0:train_size], X[train_size:]
        # walk-forward validation
        history = [x for x in train]
        predictions = list()
        for i in range(len(test)):
            # difference data
            months_in_year = 12
            diff = difference(history, months_in_year)
            # predict
            model = ARIMA(diff, mset)
            model_fit = model.fit(trend='nc', disp=0)
            yhat = model_fit.forecast()[0]
            yhat = inverse_difference(history, yhat, months_in_year)
            predictions.append(yhat)
            # observation
            obs = test[i]
            history.append(obs)
        # errors
        residuals = [test[i]-predictions[i] for i in range(len(test))]
        residuals = DataFrame(residuals)
        print(residuals.describe())
        # plot
        pyplot.figure()
        pyplot.subplot(211)
        plot_acf(residuals, ax=pyplot.gca())
        pyplot.subplot(212)
        plot_pacf(residuals, ax=pyplot.gca())
        pyplot.savefig('figure9.png')
        
        #finalize model
        
        
        # monkey patch around bug in ARIMA class
        def __getnewargs__(self):
            return ((self.endog),(self.k_lags, self.k_diff, self.k_ma))
        
        ARIMA.__getnewargs__ = __getnewargs__
        
        # create a differenced series
        def difference(dataset, interval=1):
            diff = list()
            for i in range(interval, len(dataset)):
                value = dataset[i] - dataset[i - interval]
                diff.append(value)
            return diff
        
        # load data
        series = read_csv('dataset.csv', header=None, index_col=0, parse_dates=True, squeeze=True)
        # prepare data
        X = series.values
        X = X.astype('float32')
        # difference data
        months_in_year = 12
        diff = difference(X, months_in_year)
        # fit model
        model = ARIMA(diff, mset)
        model_fit = model.fit(trend='nc', disp=0)
        # bias constant, could be calculated from in-sample mean residual
        bias = 86.775863
        # save model
        model_fit.save('model.pkl')
        numpy.save('model_bias.npy', [bias])
        
        #make prediction
        
        
        # invert differenced value
        
        
        
        series = read_csv('dataset.csv', header=None, index_col=0, parse_dates=True, squeeze=True)
        months_in_year = 12
        model_fit = ARIMAResults.load('model.pkl')
        bias = numpy.load('model_bias.npy')
        yhat = float(model_fit.forecast()[0])
        yhat = bias + inverse_difference(series.values, yhat, months_in_year)
        print('Predicted: %.3f' % yhat)
        
        
        #validate model
        
        
        # create a differenced series
        def difference(dataset, interval=1):
            diff = list()
            for i in range(interval, len(dataset)):
                value = dataset[i] - dataset[i - interval]
                diff.append(value)
            return diff
        
        # invert differenced value
        
        
        
        # load and prepare datasets
        series = read_csv('dataset.csv', header=None, index_col=0, parse_dates=True, squeeze=True)
        X = series.values.astype('float32')
        history = [x for x in X]
        months_in_year = 12
        validation = read_csv('validation.csv', header=None, index_col=0, parse_dates=True, squeeze=True)
        y = validation.values.astype('float32')
        # load model
        model_fit = ARIMAResults.load('model.pkl')
        bias = numpy.load('model_bias.npy')
        # make first prediction
        predictions = list()
        yhat = float(model_fit.forecast()[0])
        yhat = bias + inverse_difference(history, yhat, months_in_year)
        predictions.append(yhat)
        history.append(y[0])
        print('>Predicted=%.3f, Expected=%3.f' % (yhat, y[0]))
        # rolling forecasts
        for i in range(1, len(y)):
            # difference data
            months_in_year = 12
            diff = difference(history, months_in_year)
            # predict
            model = ARIMA(diff, mset)
            model_fit = model.fit(trend='nc', disp=0)
            yhat = model_fit.forecast()[0]
            yhat = bias + inverse_difference(history, yhat, months_in_year)
            predictions.append(yhat)
            # observation
            obs = y[i]
            history.append(obs)
            print('>Predicted=%.3f, Expected=%3.f' % (yhat, obs))
        prediction = DataFrame(predictions, columns=['predictions']).to_csv('predictionbyarima.csv')
        # report performance
        mse = mean_squared_error(y, predictions)
        rmse = sqrt(mse)
        print('RMSE: %.3f' % rmse)
        pyplot.plot(y)
        pyplot.plot(predictions, color='red')
        pyplot.savefig('figure10.png')
        messagebox.showinfo("Completed","Successfully Forecasted Sales")
    except Exception as e:
        messagebox.showerror(str(e))

class Toplevel1:
   
    def updatepr(self,top=None):
        global valto
        valto = 10
        global vals
        vals='''10%'''
        self.prbar_show = ttk.Progressbar(self.main_frame)
        self.prbar_show.place(relx=0.13, rely=0.596, relwidth=0.719
                , relheight=0.0, height=22)
        self.prbar_show.configure(length="720")
        
        self.lbl_prbar = tk.Label(self.main_frame)
        self.lbl_prbar.place(relx=0.859, rely=0.596, height=21, width=44)
        self.lbl_prbar.configure(background="#e6cce1")
        self.lbl_prbar.configure(disabledforeground="#a3a3a3")
        self.lbl_prbar.configure(font="-family {Segoe UI} -size 8")
        self.lbl_prbar.configure(foreground="#000000")        
        self.lbl_prbar.configure(text=vals)
        
        self.prbar_show.configure(value=valto)
    
    def __init__(self, top=None):
        '''This class configures and populates the toplevel window.
           top is the toplevel containing window.'''
        _bgcolor = '#d9d9d9'  # X11 color: 'gray85'
        _fgcolor = '#000000'  # X11 color: 'black'
        _compcolor = '#d9d9d9' # X11 color: 'gray85'
        _ana1color = '#d9d9d9' # X11 color: 'gray85'
        _ana2color = '#ececec' # Closest X11 color: 'gray92'
        self.style = ttk.Style()
        if sys.platform == "win32":
            self.style.theme_use('winnative')
        self.style.configure('.',background=_bgcolor)
        self.style.configure('.',foreground=_fgcolor)
        self.style.configure('.',font="TkDefaultFont")
        self.style.map('.',background=
            [('selected', _compcolor), ('active',_ana2color)])

        top.geometry("1001x671+309+96")
        top.minsize(120, 1)
        top.maxsize(1924, 1061)
        top.resizable(1,  1)
        top.title("Smart Sales Forecasting")
        top.configure(background="#d9d9d9")

        self.main_frame = tk.Frame(top)
        self.main_frame.place(relx=0.0, rely=0.0, relheight=1.0, relwidth=1.0)
        self.main_frame.configure(relief='groove')
        self.main_frame.configure(borderwidth="2")
        self.main_frame.configure(relief="groove")
        self.main_frame.configure(background="#cce4e6")

        self.tft_file = tk.Text(self.main_frame)
        self.tft_file.place(relx=0.19, rely=0.179, relheight=0.049
                , relwidth=0.472)
        self.tft_file.configure(background="white")
        self.tft_file.configure(cursor="fleur")
        self.tft_file.configure(font="-family {Segoe UI} -size 9")
        self.tft_file.configure(foreground="black")
        self.tft_file.configure(highlightbackground="#d9d9d9")
        self.tft_file.configure(highlightcolor="black")
        self.tft_file.configure(insertbackground="black")
        self.tft_file.configure(selectbackground="blue")
        self.tft_file.configure(selectforeground="white")
        self.tft_file.configure(wrap="word")
        self.tooltip_font = "TkDefaultFont"
        self.tft_file_tooltip = \
        ToolTip(self.tft_file, self.tooltip_font, '''Select Dataset to Predict Sales''')

        self.lbl_top = tk.Label(self.main_frame)
        self.lbl_top.place(relx=0.248, rely=0.0, height=31, width=491)
        self.lbl_top.configure(background="#cecee3")
        self.lbl_top.configure(disabledforeground="#a3a3a3")
        self.lbl_top.configure(font="-family {Segoe UI} -size 14 -weight bold")
        self.lbl_top.configure(foreground="#257e92")
        self.lbl_top.configure(text='''SmartSales Forecasting Features''')
        
        def  clicked():
            global loaddataset, series
            loaddataset = filedialog.askopenfilename()
            self.tft_file.insert(tk.END,loaddataset)
            #loaddatasetname = os.path.basename(loaddataset)
            series = read_csv(loaddataset, header=None,skiprows=1, index_col=0, parse_dates=True, squeeze=True)

        self.btn_open = ttk.Button(self.main_frame, command= clicked)
        self.btn_open.place(relx=0.679, rely=0.179, height=35, width=106)
        self.btn_open.configure(takefocus="")
        self.btn_open.configure(text='''Open Dataset''')

        def checktftfile():
            datasetfile = self.tft_file.get("1.0",'end-1c')
            if(datasetfile==""):
                messagebox.showerror("Dataset Error","Could not find the dataset")
            else:
                #Toplevel1.updatepr(self)
                startpredictionarima()
        
        def checktftfiledaily():
            datasetfile = self.tft_file.get("1.0",'end-1c')
            if(datasetfile==""):
                messagebox.showerror("Dataset Error","Could not find the dataset")
            else:
                #Toplevel1.updatepr(self)
                global df
                df = read_csv('Daily_sales.csv',delimiter=';',index_col='date')
                startpredictiondaily()   

        def parser(x):
        	return datetime.strptime('190'+x, '%Y-%m')        
                
        def checktftfilernn():
            datasetfile = self.tft_file.get("1.0",'end-1c')
            if(datasetfile==""):
                messagebox.showerror("Dataset Error","Could not find the dataset")
            else:
                #Toplevel1.updatepr(self)
                global rnnseries
                rnnseries = read_csv('datasetforRNN.csv', header=0, parse_dates=[0], index_col=0, squeeze=True, date_parser=parser)
                startpredictionrnn()

        # self.btn_start = ttk.Button(self.main_frame, command=checktftfile)
        # self.btn_start.place(relx=0.37, rely=0.268, height=35, width=156)
        # self.btn_start.configure(takefocus="")
        # self.btn_start.configure(text='''Start Forecasting''')
        
        self.btn_start = ttk.Button(self.main_frame, command=checktftfile)
        self.btn_start.place(relx=0.21, rely=0.268, height=45, width=186)
        self.btn_start.configure(takefocus="")
        self.btn_start.configure(text='''Start Sale Forecasting Monthly''')

        self.btn_startdaily = ttk.Button(self.main_frame, command=checktftfiledaily)
        self.btn_startdaily.place(relx=0.461, rely=0.268, height=45, width=196)
        self.btn_startdaily.configure(takefocus="")
        self.btn_startdaily.configure(text='''Start Sale Forecasting Daily''')

        self.btn_startrnn = ttk.Button(self.main_frame, command=checktftfilernn)
        self.btn_startrnn.place(relx=0.32, rely=0.387, height=45, width=216)
        self.btn_startrnn.configure(takefocus="")
        self.btn_startrnn.configure(text='''Start Sessional Forecasting''')

        # self.lbl_msginfo = tk.Label(self.main_frame)
        # self.lbl_msginfo.place(relx=0.22, rely=0.566, height=21, width=504)
        # self.lbl_msginfo.configure(background="#d9d9d9")
        # self.lbl_msginfo.configure(disabledforeground="#a3a3a3")
        # self.lbl_msginfo.configure(foreground="#000000")
        
# ======================================================
# Support code for Balloon Help (also called tooltips).
# Found the original code at:
# http://code.activestate.com/recipes/576688-tooltip-for-tkinter/
# Modified by Rozen to remove Tkinter import statements and to receive
# the font as an argument.
# ======================================================

from time import time, localtime, strftime

class ToolTip(tk.Toplevel):
    """
    Provides a ToolTip widget for Tkinter.
    To apply a ToolTip to any Tkinter widget, simply pass the widget to the
    ToolTip constructor
    """
    
    def __init__(self, wdgt, tooltip_font, msg=None, msgFunc=None,
                 delay=0.5, follow=True):
        """
        Initialize the ToolTip

        Arguments:
          wdgt: The widget this ToolTip is assigned to
          tooltip_font: Font to be used
          msg:  A static string message assigned to the ToolTip
          msgFunc: A function that retrieves a string to use as the ToolTip text
          delay:   The delay in seconds before the ToolTip appears(may be float)
          follow:  If True, the ToolTip follows motion, otherwise hides
        """
        self.wdgt = wdgt
        # The parent of the ToolTip is the parent of the ToolTips widget
        self.parent = self.wdgt.master
        # Initalise the Toplevel
        tk.Toplevel.__init__(self, self.parent, bg='black', padx=1, pady=1)
        # Hide initially
        self.withdraw()
        # The ToolTip Toplevel should have no frame or title bar
        self.overrideredirect(True)

        # The msgVar will contain the text displayed by the ToolTip
        self.msgVar = tk.StringVar()
        if msg is None:
            self.msgVar.set('No message provided')
        else:
            self.msgVar.set(msg)
        self.msgFunc = msgFunc
        self.delay = delay
        self.follow = follow
        self.visible = 0
        self.lastMotion = 0
        # The text of the ToolTip is displayed in a Message widget
        tk.Message(self, textvariable=self.msgVar, bg='#FFFFDD',
                font=tooltip_font,
                aspect=1000).grid()

        # Add bindings to the widget.  This will NOT override
        # bindings that the widget already has
        self.wdgt.bind('<Enter>', self.spawn, '+')
        self.wdgt.bind('<Leave>', self.hide, '+')
        self.wdgt.bind('<Motion>', self.move, '+')

    def spawn(self, event=None):
        """
        Spawn the ToolTip.  This simply makes the ToolTip eligible for display.
        Usually this is caused by entering the widget

        Arguments:
          event: The event that called this funciton
        """
        self.visible = 1
        # The after function takes a time argument in milliseconds
        self.after(int(self.delay * 1000), self.show)

    def show(self):
        """
        Displays the ToolTip if the time delay has been long enough
        """
        if self.visible == 1 and time() - self.lastMotion > self.delay:
            self.visible = 2
        if self.visible == 2:
            self.deiconify()

    def move(self, event):
        """
        Processes motion within the widget.
        Arguments:
          event: The event that called this function
        """
        self.lastMotion = time()
        # If the follow flag is not set, motion within the
        # widget will make the ToolTip disappear
        #
        if self.follow is False:
            self.withdraw()
            self.visible = 1

        # Offset the ToolTip 10x10 pixes southwest of the pointer
        self.geometry('+%i+%i' % (event.x_root+20, event.y_root-10))
        try:
            # Try to call the message function.  Will not change
            # the message if the message function is None or
            # the message function fails
            self.msgVar.set(self.msgFunc())
        except:
            pass
        self.after(int(self.delay * 1000), self.show)

    def hide(self, event=None):
        """
        Hides the ToolTip.  Usually this is caused by leaving the widget
        Arguments:
          event: The event that called this function
        """
        self.visible = 0
        self.withdraw()

    def update(self, msg):
        """
        Updates the Tooltip with a new message. Added by Rozen
        """
        self.msgVar.set(msg)

# ===========================================================
#                   End of Class ToolTip
# ===========================================================

if __name__ == '__main__':
    vp_start_gui()





